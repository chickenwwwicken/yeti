Insertion sort has a Big O of `O(n^2)`, because that is its _worst case_ complexity.

The outer loop of insertion sort always executes `n` times, while the inner loop depends on the input.

- **Best case**: If the data is pre-sorted, insertion sort becomes really fast. Can you see why?
- **Average case**: The average case is `O(n^2)` because the inner loop will execute about half of the time.
- **Worst case**: If the data is in reverse order, it's still `O(n^2)` and the inner loop will execute every time.

## Reference

```python
def insertion_sort(nums):
    for i in range(len(nums)):
        j = i
        while j > 0 and nums[j - 1] > nums[j]:
            nums[j], nums[j - 1] = nums[j - 1], nums[j]
            j -= 1
    return nums
```

### Questions 
- What is insertion sort's big o complexity? - O(n^2)
- What is insertion sort's big O complexity on a pre-sorted array? O(n)

## Why use Insertion Sort
- **Fast**: for very small data sets (even faster than merge sort and quick sort, which we'll cover later)
- **Adaptive**: Faster for partially sorted data sets
- **Stable**: Does not change the relative order of elements with equal keys
- **In-Place**: Only requires a constant amount of memory
- **Inline**: Can sort a list as it receives it

## Why Is Insertion Sort Fast for Small Lists?

Many production sorting implementations use insertion sort for very small inputs under a certain threshold (very small, like `10`-ish), and switch to something like quicksort for larger inputs. They use insertion sort because:

- There is no recursion overhead
- It has a tiny memory footprint
- It's a stable sort as described above

### Questions
- Is insertion sort useful in production systems? - yes, but only on very small inputs
- Which algorithm uses the least memory, and which is generally faster respectively? - insertion sort, merge sort

---
[[4.6_insertion-sort]]
[[4.8_quick-sort]]
