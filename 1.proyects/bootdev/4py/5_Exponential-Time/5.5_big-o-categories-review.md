| Big-O          | Name           | Description                                                                                                                                                                                      |
| -------------- | -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **O(1)**       | constant       | **Best** The algorithm always takes the same amount of time, regardless of how much data there is. Example: Looking up an item in a list by index                                                |
| **O(log n)**   | logarithmic    | **Great** Algorithms that remove a percentage of the total steps with each iteration. Very fast, even with large amounts of data. Example: Binary search                                         |
| **O(n)**       | linear         | **Good** 100 items, 100 units of work. 200 items, 200 units of work. This is usually the case for a single, non-nested loop. Example: unsorted array search.                                     |
| **O(n log n)** | "linearithmic" | **Okay** This is slightly worse than linear, but not too bad. Example: mergesort and other "fast" sorting algorithms.                                                                            |
| **O(n^2)**     | quadratic      | **Slow** The amount of work is the square of the input size. 10 inputs, 100 units of work. 100 Inputs, 10,000 units of work. Example: A nested for loop to find all the ordered pairs in a list. |
| **O(n^3)**     | cubic          | **Slower** If you have 100 items, this does 100^3 = 1,000,000 units of work. Example: A triple nested for loop to find all the ordered triples in a list.                                        |
| **O(2^n)**     | exponential    | **Horrible** We want to avoid this kind of algorithm at all costs. Adding one to the input _doubles_ the amount of steps. Example: Brute-force guessing results of a sequence of `n` coin flips. |
| **O(n!)**      | factorial      | **Even More Horrible** The algorithm becomes so slow so fast, that is practically unusable. Example: Generating all the permutations of a list                                                   |

![More Categories](https://raw.githubusercontent.com/pavankat/big-o-in-plain-english/master/most-of-them.png)

### Questions
- Which algorithm tends to be fastest
	- O(n)

### Complexity Quiz - Example 1
Consider the following code:
``` python
# names is an array of strings
def get_name_at_index(names, i):
	return names[i]
```
- What is the Big O complexity of the function?
	- O(1)

### Complexity Quiz - Example 2
Consider the following code. It calculates the number of times a given number can be divided by `2` before becoming less than or equal to `1`. 
``` python
def naive_log2(x):
	count = 0 
	while x > 1:
		x /= 2
		count += 1
	return count
```
**Questions**
What is the big O complexity of the function?
- O(log(n))

### Complexity Quiz - Example 3
Consider the following function for two questions:
``` python
#  halvedSections returns a list of lists.
#  For example, n=12 results in:
#    [
#       [0 1 2 3 4 5 6 7 8 9 10 11 12]
#       [0 1 2 3 4 5 6]
#       [0 1 2 3]
#       [0 1]
#    ]
def halved_sections(n):
    rows = []
    i = n
    while i > 0:
        col = []
        for j in range(i+1):
            col.append(j)
        rows.append(col)
        i //= 2
    return rows
```
It has a specific time complexity of:  
`T(n) = O(n + n/2 + n/4 + ...1)`
**Questions**
- What is an equivalent (but not fully reduced) way to express the complexity?
	- O(2n)
- What is the most reduced form of the function's complexity
	- O(n)

---
[[5.4_order-2^n-exponential]]
[[5.6_c1_exponential-growth-sequences]]
